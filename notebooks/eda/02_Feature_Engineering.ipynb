{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# BigMart Sales Prediction - Feature Engineering\n",
                "\n",
                "## 1. Import Libraries & Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "%matplotlib inline\n",
                "sns.set_style('whitegrid')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_df = pd.read_csv('../dataset/processed/cleaned_train.csv')\n",
                "test_df = pd.read_csv('../dataset/processed/cleaned_test.csv')\n",
                "\n",
                "print(\"Train Shape:\", train_df.shape)\n",
                "print(\"Test Shape:\", test_df.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Feature Generation\n",
                "\n",
                "### Outlet_Years\n",
                "The dataset is from 2013. We can create a new feature `Outlet_Years` indicating how old the outlet is."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_df['Outlet_Years'] = 2013 - train_df['Outlet_Establishment_Year']\n",
                "test_df['Outlet_Years'] = 2013 - test_df['Outlet_Establishment_Year']\n",
                "\n",
                "print(train_df[['Outlet_Establishment_Year', 'Outlet_Years']].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Item_Type_Combined\n",
                "Simplifying `Item_Type` into broader categories might help."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_df['Item_Type_Combined'] = train_df['Item_Identifier'].apply(lambda x: x[0:2])\n",
                "train_df['Item_Type_Combined'] = train_df['Item_Type_Combined'].map({'FD': 'Food', 'NC': 'Non-Consumable', 'DR': 'Drinks'})\n",
                "\n",
                "test_df['Item_Type_Combined'] = test_df['Item_Identifier'].apply(lambda x: x[0:2])\n",
                "test_df['Item_Type_Combined'] = test_df['Item_Type_Combined'].map({'FD': 'Food', 'NC': 'Non-Consumable', 'DR': 'Drinks'})\n",
                "\n",
                "print(train_df['Item_Type_Combined'].value_counts())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Categorical Encoding\n",
                "\n",
                "Using Label Encoding for ordinal variables and One-Hot Encoding for nominal variables.\n",
                "For this baseline, let's use Label Encoding for simplicity on some, or One-Hot for everything. Model requirements vary. \n",
                "Let's Label Encode `Outlet_Size`, `Outlet_Location_Type`, and One-Hot `Item_Fat_Content`, `Outlet_Type`, `Item_Type_Combined`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "le = LabelEncoder()\n",
                "\n",
                "cols_to_encode = ['Outlet_Size', 'Outlet_Location_Type']\n",
                "\n",
                "for col in cols_to_encode:\n",
                "    train_df[col] = le.fit_transform(train_df[col])\n",
                "    test_df[col] = le.fit_transform(test_df[col])\n",
                "\n",
                "# One-Hot Encoding\n",
                "train_df = pd.get_dummies(train_df, columns=['Item_Fat_Content', 'Outlet_Type', 'Item_Type_Combined'])\n",
                "test_df = pd.get_dummies(test_df, columns=['Item_Fat_Content', 'Outlet_Type', 'Item_Type_Combined'])\n",
                "\n",
                "print(\"Train Shape after encoding:\", train_df.shape)\n",
                "print(\"Test Shape after encoding:\", test_df.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Drop Unnecessary Columns\n",
                "Dropping `Item_Identifier`, `Outlet_Identifier`, `Item_Type` (since we have combined), and `Outlet_Establishment_Year` (since we have Years)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cols_to_drop = ['Item_Identifier', 'Outlet_Identifier', 'Item_Type', 'Outlet_Establishment_Year']\n",
                "# Be careful to drop only what exists. Some might have been dropped or transformed.\n",
                "\n",
                "train_df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
                "test_df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
                "\n",
                "# Store IDs separately if needed for submission, but for training we drop them.\n",
                "# We should probably keep IDs in a separate dataframe for submission matching before dropping."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save Feature Engineered Data\n",
                "train_df.to_csv('../dataset/processed/feat_eng_train.csv', index=False)\n",
                "test_df.to_csv('../dataset/processed/feat_eng_test.csv', index=False)\n",
                "\n",
                "print(\"Feature Engineered data saved.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}