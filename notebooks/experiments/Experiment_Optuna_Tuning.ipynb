{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Optuna Hyperparameter Tuning\n",
                "\n",
                "This notebook uses Optuna to find the best hyperparameters for XGBoost."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import optuna\n",
                "import mlflow\n",
                "import mlflow.sklearn\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import KFold, cross_val_score\n",
                "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.metrics import mean_squared_error\n",
                "from xgboost import XGBRegressor\n",
                "import os\n",
                "import json\n",
                "\n",
                "# Set MLflow experiment\n",
                "mlflow.set_experiment(\"BigMart_Sales_Optimization\")\n",
                "\n",
                "# Load Data\n",
                "processed_dir = r'c:\\Storage\\Smartapps\\ABB Use case\\Big_mart_sales_prediction\\dataset\\processed'\n",
                "train_path = os.path.join(processed_dir, 'feat_eng_train.csv')\n",
                "train_df = pd.read_csv(train_path)\n",
                "\n",
                "# Separate features and target\n",
                "X = train_df.drop('Item_Outlet_Sales', axis=1)\n",
                "y = train_df['Item_Outlet_Sales']\n",
                "\n",
                "# Drop non-numeric identifier columns\n",
                "cols_to_drop = ['Item_Identifier', 'Outlet_Identifier', 'Item_Type']\n",
                "X = X.drop(columns=cols_to_drop, errors='ignore')\n",
                "if 'Outlet_Establishment_Year' in X.columns:\n",
                "    X = X.drop(columns=['Outlet_Establishment_Year'])\n",
                "\n",
                "print(\"Training Features:\", X.columns.tolist())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def objective(trial):\n",
                "    with mlflow.start_run(nested=True):\n",
                "        # 1. Suggest Scaler\n",
                "        scaler_name = trial.suggest_categorical(\"scaler\", [\"Standard\", \"MinMax\", \"Robust\"])\n",
                "        if scaler_name == \"Standard\":\n",
                "            scaler = StandardScaler()\n",
                "        elif scaler_name == \"MinMax\":\n",
                "            scaler = MinMaxScaler()\n",
                "        else:\n",
                "            scaler = RobustScaler()\n",
                "            \n",
                "        # 2. Suggest XGBoost Hyperparameters\n",
                "        param = {\n",
                "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
                "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
                "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
                "            \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
                "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
                "            \"random_state\": 42,\n",
                "            \"n_jobs\": -1\n",
                "        }\n",
                "        \n",
                "        # 3. Create Pipeline\n",
                "        model = XGBRegressor(**param)\n",
                "        pipeline = Pipeline([\n",
                "            (\"scaler\", scaler),\n",
                "            (\"model\", model)\n",
                "        ])\n",
                "        \n",
                "        # 4. Cross-Validation\n",
                "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
                "        # XGBoost minimizes MSE, but we want RMSE.\n",
                "        scores = cross_val_score(pipeline, X, y, cv=kf, scoring=\"neg_root_mean_squared_error\")\n",
                "        rmse = -scores.mean()\n",
                "        \n",
                "        # 5. Log to MLflow\n",
                "        mlflow.log_params(param)\n",
                "        mlflow.log_param(\"scaler\", scaler_name)\n",
                "        mlflow.log_metric(\"cv_rmse\", rmse)\n",
                "        \n",
                "        return rmse"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Starting Optuna optimization...\")\n",
                "study = optuna.create_study(direction=\"minimize\")\n",
                "study.optimize(objective, n_trials=20) \n",
                "\n",
                "print(\"\\nBest trial:\")\n",
                "trial = study.best_trial\n",
                "print(f\"  Value: {trial.value}\")\n",
                "print(\"  Params: \")\n",
                "for key, value in trial.params.items():\n",
                "    print(f\"    {key}: {value}\")\n",
                "    \n",
                "# Save best params to JSON for use in other notebooks\n",
                "with open(\"best_params.json\", \"w\") as f:\n",
                "    json.dump(trial.params, f, indent=4)\n",
                "print(\"Saved best_params.json\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Retrain best model on full data and log artifacts\n",
                "print(\"\\nRetraining best model and logging artifacts...\")\n",
                "with mlflow.start_run(run_name=\"Best_Model\"):\n",
                "    # Reconstruct best pipeline\n",
                "    best_params = trial.params.copy()\n",
                "    scaler_name = best_params.pop(\"scaler\")\n",
                "    \n",
                "    if scaler_name == \"Standard\":\n",
                "        scaler = StandardScaler()\n",
                "    elif scaler_name == \"MinMax\":\n",
                "        scaler = MinMaxScaler()\n",
                "    else:\n",
                "        scaler = RobustScaler()\n",
                "        \n",
                "    model = XGBRegressor(**best_params, random_state=42, n_jobs=-1)\n",
                "    pipeline = Pipeline([\n",
                "        (\"scaler\", scaler),\n",
                "        (\"model\", model)\n",
                "    ])\n",
                "    \n",
                "    pipeline.fit(X, y)\n",
                "    \n",
                "    # Log params and metrics\n",
                "    mlflow.log_params(best_params)\n",
                "    mlflow.log_param(\"scaler\", scaler_name)\n",
                "    mlflow.log_metric(\"final_rmse\", trial.value)\n",
                "    \n",
                "    # Log model\n",
                "    mlflow.sklearn.log_model(pipeline, \"model\")\n",
                "    \n",
                "    # Create and log plots\n",
                "    y_pred = pipeline.predict(X)\n",
                "    \n",
                "    # Actual vs Predicted Plot\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    sns.scatterplot(x=y, y=y_pred, alpha=0.5)\n",
                "    plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
                "    plt.xlabel(\"Actual Sales\")\n",
                "    plt.ylabel(\"Predicted Sales\")\n",
                "    plt.title(f\"Actual vs Predicted (RMSE: {trial.value:.2f})\")\n",
                "    plt.savefig(\"actual_vs_predicted.png\")\n",
                "    mlflow.log_artifact(\"actual_vs_predicted.png\")\n",
                "    plt.close()\n",
                "    \n",
                "    # Residual Plot\n",
                "    residuals = y - y_pred\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    sns.distplot(residuals)\n",
                "    plt.title(\"Residuals Distribution\")\n",
                "    plt.xlabel(\"Residual\")\n",
                "    plt.savefig(\"residuals.png\")\n",
                "    mlflow.log_artifact(\"residuals.png\")\n",
                "    plt.close()\n",
                "    \n",
                "    print(\"Optimization complete. Check MLflow for details.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}