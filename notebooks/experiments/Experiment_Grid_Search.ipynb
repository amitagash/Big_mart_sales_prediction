{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Grid Search Tuning\n",
                "\n",
                "This notebook performs Grid Search to fine-tune XGBoost parameters, potentially initiating from Optuna's best parameters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import mlflow\n",
                "import mlflow.sklearn\n",
                "import json\n",
                "import os\n",
                "from sklearn.model_selection import GridSearchCV, KFold\n",
                "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
                "from sklearn.pipeline import Pipeline\n",
                "from xgboost import XGBRegressor\n",
                "\n",
                "# Set MLflow\n",
                "mlflow.set_experiment(\"BigMart_Sales_GridSearch\")\n",
                "\n",
                "# Load Data\n",
                "processed_dir = r'c:\\Storage\\Smartapps\\ABB Use case\\Big_mart_sales_prediction\\dataset\\processed'\n",
                "train_path = os.path.join(processed_dir, 'feat_eng_train.csv')\n",
                "train_df = pd.read_csv(train_path)\n",
                "\n",
                "# Prepare Data\n",
                "X = train_df.drop('Item_Outlet_Sales', axis=1)\n",
                "y = train_df['Item_Outlet_Sales']\n",
                "\n",
                "cols_to_drop = ['Item_Identifier', 'Outlet_Identifier', 'Item_Type']\n",
                "X = X.drop(columns=cols_to_drop, errors='ignore')\n",
                "if 'Outlet_Establishment_Year' in X.columns:\n",
                "    X = X.drop(columns=['Outlet_Establishment_Year'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best params from Optuna to center the grid\n",
                "# Assuming best_params.json is in the current directory if generated by Optuna experiment\n",
                "params_path = 'best_params.json'\n",
                "\n",
                "try:\n",
                "    with open(params_path, 'r') as f:\n",
                "        best_optuna_params = json.load(f)\n",
                "    print(\"Loaded Optuna params:\", best_optuna_params)\n",
                "    \n",
                "    # Extract centers (casting to appropriate types)\n",
                "    center_n_est = int(best_optuna_params.get('n_estimators', 100))\n",
                "    center_depth = int(best_optuna_params.get('max_depth', 5))\n",
                "    center_lr = float(best_optuna_params.get('learning_rate', 0.1))\n",
                "    \n",
                "    # Define Grid around these values\n",
                "    param_grid = {\n",
                "        'model__n_estimators': [center_n_est - 50, center_n_est, center_n_est + 50],\n",
                "        'model__max_depth': [center_depth - 1, center_depth, center_depth + 1],\n",
                "        'model__learning_rate': [center_lr * 0.9, center_lr, center_lr * 1.1],\n",
                "        # Keep some fixed or narrow\n",
                "        'model__subsample': [0.8, 0.9], \n",
                "        'model__colsample_bytree': [0.8, 0.9]\n",
                "    }\n",
                "    \n",
                "    # Scaler selection\n",
                "    scaler_type = best_optuna_params.get('scaler', 'Robust')\n",
                "    if scaler_type == 'Standard':\n",
                "        scaler = StandardScaler()\n",
                "    elif scaler_type == 'MinMax':\n",
                "        scaler = MinMaxScaler()\n",
                "    else:\n",
                "        scaler = RobustScaler()\n",
                "        \n",
                "    print(f\"Using Scaler: {scaler_type}\")\n",
                "    print(\"Grid:\", param_grid)\n",
                "\n",
                "except Exception as e:\n",
                "    print(f\"Could not load best_params.json: {e}. Using default grid.\")\n",
                "    scaler = RobustScaler()\n",
                "    param_grid = {\n",
                "        'model__n_estimators': [100, 200, 300],\n",
                "        'model__max_depth': [3, 5, 7],\n",
                "        'model__learning_rate': [0.01, 0.1, 0.2]\n",
                "    }\n",
                "\n",
                "# Ensure n_estimators > 0\n",
                "param_grid['model__n_estimators'] = [x for x in param_grid['model__n_estimators'] if x > 0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pipeline\n",
                "pipeline = Pipeline([\n",
                "    ('scaler', scaler),\n",
                "    ('model', XGBRegressor(random_state=42, n_jobs=-1))\n",
                "])\n",
                "\n",
                "# GridSearchCV\n",
                "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
                "grid_search = GridSearchCV(\n",
                "    estimator=pipeline,\n",
                "    param_grid=param_grid,\n",
                "    scoring='neg_root_mean_squared_error',\n",
                "    cv=kf,\n",
                "    n_jobs=-1,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"Starting GridSearchCV...\")\n",
                "with mlflow.start_run(run_name=\"GridSearch_Run\"):\n",
                "    grid_search.fit(X, y)\n",
                "    \n",
                "    best_rmse = -grid_search.best_score_\n",
                "    best_params = grid_search.best_params_\n",
                "    \n",
                "    print(f\"\\nBest GridSearch RMSE: {best_rmse}\")\n",
                "    print(\"Best GridSearch Params:\", best_params)\n",
                "    \n",
                "    # Log to MLflow\n",
                "    mlflow.log_params(best_params)\n",
                "    mlflow.log_metric(\"best_cv_rmse\", best_rmse)\n",
                "    mlflow.sklearn.log_model(grid_search.best_estimator_, \"model\")\n",
                "    \n",
                "    # Save best grid params\n",
                "    clean_params = {k.replace('model__', ''): v for k, v in best_params.items()}\n",
                "    clean_params['scaler'] = 'Robust' # Assuming we stuck with the best scaler from Optuna\n",
                "    \n",
                "    with open(\"best_grid_params.json\", \"w\") as f:\n",
                "        json.dump(clean_params, f, indent=4)\n",
                "    print(\"Saved best_grid_params.json\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}